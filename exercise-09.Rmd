---
title: "exercise-09"
author: "Jyhreh Johnson"
date: "3/30/2022"
output: html_document
---
1. Using the {tidyverse} read_csv() function, load the “Street_et_al_2017.csv” dataset from this URL as a “tibble” named d

Do a quick exploratory data analysis where you generate the five-number summary (median, minimum and maximum and 1st and 3rd quartile values), plus mean and standard deviation, for each quantitative variable
```{r}
library(tidyverse)
library(broom)
library(patchwork)
library(infer)
library(lmodel2)
library(skimr)
f <- "https://raw.githubusercontent.com/difiore/ada-2022-datasets/main/Street_et_al_2017.csv"
d <- read_csv(f, col_names = TRUE)
head(d)
```
2. Do a quick exploratory data analysis where you generate the five-number summary (median, minimum and maximum and 1st and 3rd quartile values), plus mean and standard deviation, for each quantitative variable
```{r}
skim(d)
```
3. From this dataset, plot brain size (ECV) as a function of social group size (Group_size), longevity (Longevity), juvenile period length (Weaning), and reproductive lifespan (Repro_lifespan)
```{r}
gs_plot <- ggplot(data = d, aes(x = ECV, y = Group_size)) + geom_point()
long_plot <- ggplot(data = d, aes(x = ECV, y = Longevity)) + geom_point()
wean_plot <- ggplot(data = d, aes(x = ECV, y = Weaning)) + geom_point()
repro_plot<- ggplot(data = d, aes(x = ECV, y = Repro_lifespan)) + geom_point()

gs_plot + long_plot + wean_plot + repro_plot
```
4. From this dataset, plot brain size (ECV) as a function of social group size (Group_size), longevity (Longevity), juvenile period length (Weaning), and reproductive lifespan (Repro_lifespan) Derive by hand the ordinary least squares regression coefficients β code = $\beta$ and β code = $\beta$for ECV as a function of social group size. 
```{r}
d_mod <- d %>% filter(!is.na(ECV) & !is.na(Group_size))

beta1 <- cor(d_mod$ECV, d_mod$Group_size) * sd(d_mod$ECV) / sd(d_mod$Group_size)
beta1

beta0 <- mean(d_mod$ECV) - beta1 * mean(d_mod$Group_size)
beta0
```

5. Confirm that you get the same results using the lm() function
```{r}
model <- lm(data = d_mod, ECV ~ Group_size)
summary(model)

residuals <- d_mod$ECV - (beta0 + beta1 * d_mod$Group_size)

num <- sum(residuals^2)
den <- sum((d_mod$Group_size - mean(d_mod$Group_size))^2) * (n-2)
```
6. Repeat the analysis above for three different major radiations of primates – “catarrhines”, “platyrrhines”, and “strepsirhines”) separately. These are stored in the variable Taxonomic_group.
Do your regression coefficients differ among groups? How might you determine this?
```{r}
#Catarrhines
catarrhines <- d_mod %>% filter(Taxonomic_group == "Catarrhini")
cata_b1 <- cor(catarrhines$ECV, catarrhines$Group_size) * (sd(catarrhines$ECV)/sd(catarrhines$Group_size))
cata_b1

cata_b0 <- mean(catarrhines$ECV) - cata_b1 * mean(catarrhines$Group_size)
cata_b0

#cata lm
cata_m <- lm(formula = ECV ~ Group_size, data = catarrhines)
summary(cata_m)
```
```{r}
#Platyrrhines
platyrrhines <- d_mod %>% filter(Taxonomic_group == "Platyrrhini")
plat_b1 <- cor(platyrrhines$ECV, platyrrhines$Group_size) * (sd(platyrrhines$ECV)/sd(platyrrhines$Group_size))
plat_b1

plat_b0 <- mean(platyrrhines$ECV) - plat_b1 * mean(platyrrhines$Group_size)
plat_b0

#plat lm
plat_m <- lm(formula = ECV ~ Group_size, data = platyrrhines)
summary(plat_m)
```
```{r}
#Strepsirhines
strepsirhines <- d_mod %>% filter(Taxonomic_group == "Strepsirhini")
strep_b1 <- cor(strepsirhines$ECV, strepsirhines$Group_size) * (sd(strepsirhines$ECV)/sd(strepsirhines$Group_size))
strep_b1

strep_b0 <- mean(strepsirhines$ECV) - cata_b1 * mean(strepsirhines$Group_size)
strep_b0

#strep lm
strep_m <- lm(formula = ECV ~ Group_size, data = strepsirhines)
summary(strep_m)
```
7. Do your regression coefficients differ among groups? How might you determine this?
-The regression coefficients differ slightly among groups. You can determine this by comparing the summaries of each group's linear model found with the lm() function.

8. For your first regression of ECV on social group size, calculate the standard error for the slope coefficient, the 95% CI, and the p value associated with this coefficient by hand. Also extract this same information from the results of running the lm() function.
```{r}
#Find the standard error of Beta 1
SE_beta1 <- sqrt(num/den)
SE_beta1

#Calculated but not asked for:
#SE_beta0 <- SE_beta1 * sqrt(sum(d_mod$Group_size)/length(d_mod$Group_size))
#SE_beta0

#Code from class for t-values
#t_beta1 <- beta1/SE_beta1
#t_beta0 <- beta0/SE_beta0
#1 - pt(t_beta1, 149)
```
```{r}
mod.summary <- tidy(model) #summarize the model information
mod.summary

#Calculate the 95% CI, I did it the long way but a cleaner/shorter way was provided in class: (CI <- confint(model, level = 1 - alpha)) try to use this later to learn how it works
alpha <- 0.05
lower <- mod.summary$estimate -
  qt(1 - alpha / 2, df = nrow(d_mod) - 2) * mod.summary$std.error
upper <- mod.summary$estimate +
  qt(1 - alpha / 2, df = nrow(d_mod) - 2) * mod.summary$std.error
CI <- c(lower, upper)
CI
```
```{r}
#Calculate the p-value, again the long way. Im sure there is a shorter way
mod.summary$calc.statistic <- (mod.summary$estimate-0)/mod.summary$std.error
mod.summary$calc.p.value <- 2 * pt(mod.summary$calc.statistic,
  df=nrow(d_mod)-2, lower.tail = FALSE)
mod.summary

#model2 <- lm(data = mod.summary, )
#summary(model2)
```
9. Then, use a permutation approach with 1000 permutations to generate a null sampling distribution for the slope coefficient. What is it that you need to permute? What is the p value associated with your original slope coefficient? You can use either the percentile method (i.e., using quantiles from actual permutation-based null sampling distribution) or a theory-based method (i.e., using the standard deviation of the permutation-based null sampling distribution as the estimate of the standard error), or both, to calculate this p value.

```{r}
#define the alpha, CI boundaries, and critical values
conf_level <- 1 - alpha
lower_p <- alpha / 2
upper_p <- 1 - (alpha / 2)
d_freedom <- nrow(d_mod) - 2
crit_value <- qt(upper_p, df = d_freedom)
```

```{r}
#calculate the original slope 
o_slope <- lm(data = d_mod, ECV ~ Group_size) %>%
  tidy(conf.int=TRUE, conf.level=conf_level) %>% #try using the conf.int method from above
  mutate(
    lower = estimate - se * crit_value,
    upper = estimate + se * crit_value
  ) %>%
  filter(term=="Group_size")
o_slope 
```

```{r}
#calculate the permuted slope
library(mosaic)
reps = 1000 #set the number of reps for permutation

#Individual pieces of code for permutation from Module 16
p <- d_mod %>% specify(formula = ECV ~ Group_size)
head(p) #specify or select for ECV and Group_size

p1 <- p %>% hypothesize(null = "independence") #get the null hypothesis
head(p1)

p_permutation <- p1 %>% generate(reps, type = "permute") #generate the 1000 permutations

null_dist <- p_permutation %>% calculate(stat = "slope") #calculate the slope

#Combined individual code from above, call it perm_slope, and PIPE. Totally did not realize this was also code in Module 18 -_- (Will do it another way if not allowed.)
perm_slope <- d_mod %>%
  specify(formula = ECV ~ Group_size) %>% 
  hypothesize(null = "independence") %>%
  generate(reps, type = "permute") %>%
  calculate(stat = "slope")
head(perm_slope)

#Can also use do reps and for loop maybe?? Will figure out 

#Is this what you meant by the theory-based method??
perm_slope_summary <- perm_slope %>%
  summarize(
    estimate = mean(stat),
    se = sd(stat),
    lower = estimate - se * crit_value,
    upper = estimate + se * crit_value,
  )
perm_slope_summary
```
```{r}
#I tried to use the get_p_value() function, I think I did this correctly???
p_value <- perm_slope %>%
  get_p_value(obs_stat = o_slope$estimate, direction="two_sided")
p_value
```
Bootstrapping

10. Use bootstrapping to generate a 95% CI for your estimate of the slope coefficient using both the percentile method and the theory-based method (i.e., based on the standard deviation of the bootstrapped sampling distribution). What is the p value associated with your observed slope coefficient based on each of these methods?
```{r}
#Try using the same method used for the permutation above from Module 16.
b_slope <- d_mod %>%
  specify(formula = ECV ~ Group_size) %>%
  generate(reps, type = "bootstrap") %>% 
  calculate(stat = "slope") 
head(b_slope)

#Calculate the CI using the percentile method
b_CI1 <- b_slope %>%
  summarize(
    lower_b = quantile(stat, lower_p),
    upper_b = quantile(stat, upper_p)
  )

b_CI1

#Calculate the CI using theory-based method
b_CI2 <- b_slope %>%
  summarize(
    estimate = mean(stat),
    se = sd(stat),
    lower = estimate - se * crit_value,
    upper = estimate + se * crit_value,
  )
b_CI2
```

11. Do these CIs suggest that your slope coefficient is different from zero?
-Yes